---
title: "TMA4315: Compulsory exercise 2" 
subtitle: "Aurora Hofman, Camilla Karlsen, Catharina Lilleengen" 
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: html_document
---


# Problem 1

```{r setup, include=TRUE}
  filepath <- "https://www.math.ntnu.no/emner/TMA4315/2018h/mountains"
  mount <- read.table(file = filepath, header = TRUE, col.names = c("height", 
      "prominence", "fail", "success"))
  attach(mount)
```
##a) 
From the given dataset we notice that we have grouped data. This means that every covariate vector, $\vec{x_i}$, with $i=1,\ldots,G$, in the design matrix $X$ that are identical, are grouped. In our case this means that everyone that has attempted to reach the same mountain falls in the same group. We assume that the number of groups $G$ is much less then the total number of observations $n = \sum \limits_{i=1}^{G} n_i$, where $n_i$ is the number of replicates of $\vec{x_i}$. This is reasonable to assume since there are far more people who have attempted reaching an mountain in our dataset, than the number of mountains which is 113 in this case. 

The response variables $y_i$ are assumed to be independent given the covariates $x_{i1},\ldots, x_{ik}$. We also assume that each data $y_i$ are Bernoulli distributed with $P(y_i = 1) = \pi_i$. For the people attempting there is a certain probability of reaching each mountain which is $\pi_i$. So the attempt is either a success or fail. 

Because the response variables $y_i$ are independent, the absolute frequencies $n_i\bar{y_i}$ of grouped data are binomially distributed, with $E(n_i\bar{y_i}) = n_i\pi_i$ and $Var(n_i\bar{y_i}) = n_i\pi_i(1-\pi_i)$. Hence, we have a binary model because we have two response values, the number of successes and number of fails. The linear predictor in this case is 
$$
\eta_i = \beta_0 + \beta_1x_{i1} + \ldots + \beta_kx_{ik} = \mathbf{x_i}^T\mathbf{\beta}, 
$$
and $k=2$ in this case. This linear predictor is linked to $\pi_i$ via the response function, 
$$
  \pi_i = h(\eta_i).
$$
The canonical link function for a binary regression model is the logit model, which is given by
$$
  \pi_i = \frac{\exp({\eta_i})}{1+\exp({\eta_i})}.
$$
For the canonical link function the log-likelihood function is always concave so that if the maximum likelihood estimator exists it is always unique. Thus, we choose the logit  model as our link function. 

We now fit a glm modelling how the probability that an attempt at reaching a particular summit depends on its height and prominence. 
```{r, include=TRUE}
  mod <- glm(cbind(success,fail)~height+prominence, family=binomial(link = "logit"))
  summary(mod)
```

##b) 
By use of the observed deviance, we can estimate the overdispersion parameter $\phi$. We have, 
$$
  \hat{\phi} = \frac{D}{G-p}, 
$$
where $D$ is the deviance, $G$ is the number of groups and $p$ is the number of estimated regression coefficients. In the code below we estimate the observed deviance. 
```{r, include=TRUE}
  deviance <- deviance(mod)
  G <- nrow(mount)      #number of groups
  p <- ncol(mount)-1    #number of estimated regression coefficients
  phi <- deviance/(G-p)
  phi
```
From the output we see that $\hat{\phi}$ is larger than 1, thus we have overdispersion. Reasons for overdispersion can be unobserved heterogeneity and positive correlation between independent binary observations of the response variable. In this case, the data will be correlated because each individual most likely will belong to a cluster since reaching a mountain often happens in groups with a guide. Because we have overdispersion we want to refit the model using a quasi-likelihood model. 

```{r, include=TRUE}
  mod2 <- glm(cbind(success,fail)~height+prominence, family=quasibinomial(link = "logit"))
  summary(mod2)
```

##c) 
Now we want to choose the best model for our data. This means we compare models with all possible combinations of the covariates we have in our original model, hereby called the full model, and also including the model with only intercept and choose the best of them. To compare the models we look at the QAIC criterion which is given by, 
$$
  QAIC = -\frac{2l(\hat{\theta})}{\hat{\phi}} +2p, 
$$
where $l(\hat{\theta})$ is the likelihood function evaluated at the estimated regression coefficients. We let $\hat{\phi}$ be a common estimate of the overdispersion parameter under the full model, and we count $\phi$ as a estimated parameter. To compute the QAIC for the different models we start by computing the likelihood function after we have fitted non-quasi-likelihood models for the different combinations og covariates. 
```{r, include=TRUE}
  library(ISwR)

  #Full model
  likelihood = logLik(mod)
  QAIC_mod = -2*likelihood/phi+2*(p+1)
  QAIC_mod
  
  #Model with only height as covariate
  mod10 <- glm(cbind(success,fail)~height, family=binomial(link = "logit"))
  likelihood10 = logLik(mod10)
  QAIC_mod10 = -2*likelihood10/phi+2*(p)
  QAIC_mod10
  
  #Model with only prominence as covariate
  mod01 <- glm(cbind(success,fail)~prominence , family=binomial(link = "logit"))
  likelihood01 = logLik(mod01)
  QAIC_mod01 = -2*likelihood01/phi+2*(p)
  QAIC_mod01
  
  #Model with only intercept
  mod00 <- glm(cbind(success,fail)~1 , family=binomial(link = "logit"))
  likelihood00 = logLik(mod00)
  QAIC_mod00 = -2*likelihood00/phi+2*(p-1)
  QAIC_mod00
  
  #SKAL VI OGSÅ HA MED AIC FOR HVER MODEL HER??
```
By looking at the computed QAICs we see that the model with both covariates has the lowest value. Hence, we choose the full model. 

##d)
Now we want to test the significance of each term in the model using both Wald test and likelihood ratio test. 
```{r, include=TRUE}
drop1(mod2, test = "LRT")  #Skal det være mod2 her? 
summary(mod2)

#Wald test
beta <- coef(mod2)
d <- c(0,0,0)
C <- rbind(c(1,0,0),
           c(0,1,0),
           c(0,0,1))
wald <- t(C %*% beta - d) %*% solve(C %*% vcov(mod2) %*% t(C)) %*% (C %*% beta - d)
wald
pchisq(wald, df=3, lower.tail=FALSE)
```
By use of likelihood ratio test we see that each term in the model is significant. By comparing with the summary from the fitted model we see that both covariates are a bit less significant in the summary output. 

By use of the Wald test we see that the p-value is much less than any reasonable significance level. Hence, we reject the null hypothesis that the coefficient estimates are zero. Thus the coefficients are significant. 

Our choice of link function was the logit model. To interpret the estimated regression coefficients we look at the odds, 
$$
  \frac{\pi_i}{1-\pi_i} = \frac{P(y_i=1 | x_i)}{P(y_i=0 | x_i)} = \exp(\beta_0)\cdot \exp(x_{i1}\beta_1)\cdot \ldots \cdot \exp(x_{ik}\beta_k) = \exp(\eta_i). 
$$
So, if we for example increase $x_{i2}$ by one unit to $x_{i2}+1$  and keep all the other covariates constant, then we have
$$
  \frac{\pi_i}{1-\pi_i} = \exp(\beta_0)\cdot \exp(x_{i1}\beta_1)\cdot \exp((x_{i2}+1)\beta_2)\cdot \ldots \cdot \exp(x_{ik}\beta_k)
$$
$$
  = \exp(\beta_0)\cdot \exp(x_{i1}\beta_1)\cdot \exp(x_{i2}\beta_2)\cdot\exp(\beta_2)\cdot \ldots \cdot \exp(x_{ik}\beta_k) = \exp(\eta_i) \cdot\exp(\beta_2).
$$
Hence, the odds changes by $\exp(\beta_2)$. So, if $\beta_2 >0$ then $P(y_i=1)/P(y_i=0)$ increases and if $\beta_2 < 0$ then $P(y_i=1)/P(y_i=0)$ decreases. Also, if $\beta_2 = 0$ then $P(y_i=1)/P(y_i=0)$ remain unchanged. Hence, the effect of the covariates on the odds is exponentially multiplicative. 

This can also be interpreted in terms of the log-odds, 
$$
\log\left(\frac{\pi_i}{1-\pi_i}\right) = \eta_i = x_i^T\beta.
$$
We then have a linear relationship, and if we now increase $x_{i2}$ by one unit to $x_{i2}+1$ and keep all the other covariates constant, then the log-odds will change with a factor of $\beta_2$ as shown below. 
$$
\log\left(\frac{\pi_i}{1-\pi_i}\right) =  \beta_0 + \beta_1x_{i1} + \beta_2(x_{i2}+1) + \ldots + \beta_kx_{ik} = x_i^T\beta + \beta_2. 
$$
   
##e) 
```{r, include=TRUE}
library(ggplot2)
#Plotting the deviance residuals against fitted values
data = data.frame(fitted = mod2$fitted.values, res = residuals(mod2,type = "deviance"))
ggplot(data,aes(x=fitted,y = res)) + geom_point()
#Plotting the deviance residuals against the covariate height
data2 = data.frame(height, res = residuals(mod2,type = "deviance"))
ggplot(data2,aes(x=height,y = res)) + geom_point()
#Plotting the deviance residuals against the covariate prominence
data3 = data.frame(prominence, res = residuals(mod2,type = "deviance"))
ggplot(data3,aes(x=prominence,y = res)) + geom_point()

```
   
When plotting the fitted values against the residuals one can see that the data points does seem to be quite randomly spread around the horizontal axis $y=0$. Hence, we can conclude that our model fits good to our data. It also seems like the variance increase, so we do not have homoscedasisty, which means that each response is this case do not have the same variance. This is a contradiction of our assumption that the responses is Bernoulli distributed with the same variance. 

From this residual plot we can also detect possible outliers. The two data points to the left in the plot might seem like they are outliers, but it can also be that we have too few data points in this area to give an reasonable explanation. 

In the figure with the covariate height plotted against the residuals we see no systematic effect, e.g. linear or quadratic trend in the plot. Thus, we cannot say anything about how this covariate will affect the model. The same applies for the covariate prominence when we plot this against the residuals. 
   
##f) 
"The height and the prominence of Mount Everest are both 8848 meters. Compute a prediction for the probability that an attempt at this summit will be successful. First consider the predicted value and its variance on the scale of the linear predictor. Also compute a 95% confidence interval for the predicted value on this scale based on asymptotic normality of β̂ .Transform this confidence interval to the probability scale and explain the theory behind the transformation you're using.""

The height and the prominence of Mount Everest are both 8848 meters. We start by computing a prediction for the probability that an attempt at the summit will be successfull. Then we compute a 95% confidence interval for the predicted value on this scale based on asymptotic normality of $\beta$. We have assumed the responses to be Bernoulli distributed, but when $n$ is large they are approximately normal distributed. Hence, $\beta$ is asymptotic normal distributed.

In mathematical notation we find the confidence interval of $x_{new}^T*\beta$, where $x_{new} = [1,8848,8848]^T$ which is the covariate vector for Mount Everest. Since we assume $\beta$ is asymptotic normal distributed we know the linear combination $x_{new}^T*\beta$ is univariate normal distributed. So by rules of expected value and variance we have,
$$
  x_{new}^T\beta \sim N(x_{new}^T\hat{\beta},x_{new}^T\Sigma x_{new} ),
$$
where $\Sigma = Cov(\hat{\beta})$. Hence, we get a confidence interval
$$
  [x_{new}^T\hat{\beta} - z_{\alpha/2}\cdot SE(\hat{\beta}), x_{new}^T\hat{\beta} + z_{\alpha/2}\cdot SE(\hat{\beta})], 
$$
where $SE(\hat{\beta}) = \sqrt{x_{new}^T\Sigma x_{new}}$.

```{r, include=TRUE}
#Calculate CI for a predicted value
new = data.frame(height = 8848, prominence = 8848)
x_new = c(1,8848,8848)
pred = predict(mod2,newdata=new)            #The predicted probability

alpha=0.05
sigma_matrix= vcov(mod2)                    #The estimated variance matrix of β
se = sqrt(t(x_new)%*%sigma_matrix%*%x_new)  #Standard error of x^T*β

lower = pred - qnorm(1-alpha/2) * se
upper = pred + qnorm(1-alpha/2) * se
ci = c(lower, upper)      #95% confidence interval for the predicted value 
probci = plogis(ci)       #Transform the confindence interval to probability 
probci                    # scale

#Calculate CI for second height mountain in data set
new_second = data.frame(height = 8611, prominence = 4017)
x_second = c(1,8611,4017)
pred_sec = predict(mod2,newdata=new_second) 
se_sec = sqrt(t(x_second)%*%sigma_matrix%*%x_second)  #Standard error of x^T*β

lower_sec = pred_sec - qnorm(1-alpha/2) * se_sec
upper_sec = pred_sec + qnorm(1-alpha/2) * se_sec
ci_sec = c(lower_sec, upper_sec)#95% confidence interval for the predicted value 
probci = plogis(ci_sec)       #Transform the confindence interval to probability 
probci  
  
```
In the code above we first found the confidence interval in terms of the linear predictor $\eta = x^T\beta$. To transform the interval to the probability scale we have used the inverse of the logit function. Hence to transform the confidence interval we have used that, 
$$
  \pi = \frac{\exp(\eta)}{1+\exp(\eta)}.
$$
We then get the interval [0.034,0.213]. 

We know that if the prominence increase, the probability of success is lower. Mount Everest is the only mountain in our data set that have the same height and prominence. This might lead to that the model does not fit the datapoint $x_{new}$ for Mount Everest well. Thus, we might get a interval that has too low values. By comparing with the second highest mountain in our data set, which have covariate vector $x_{sec} = [1,8611,4017]^T$, we would expect that the probabilities of success is not that far from each other. The interval for the second highest mountain is [0.180,0.337]. In addition, when calculating a confidence interval for Mount Everest, but letting the prominence be more similar to the other data points in our dataset, e.g. 5000 instead, we get a interval of [0.099,0.249]. This is much more similiar to the interval for the second highest mountain. Hence, we conclude that our interval [0.034,0.213] gives a bit too low values.
   
# Problem 2

In this problem we want to use a generalized linear model to analyse part of the 2018 results from the Norwegian elite football league. 
```{r, include=TRUE}
long <- read.csv("https://www.math.ntnu.no/emner/TMA4315/2019h/eliteserie.csv")
long
```
##a)
We start by fitting a model with attack, defence and home as covariates, to the data.
```{r, include=TRUE}
mod <- glm(goals ~ attack + defence + home, poisson(link= log), data=long ) #log natural choice of link funk
summary(mod)
```

We choose the log-linear model as our link function since this is the natural choice for a poisson distribution. Further we assume that the response variables $y_i$, i.e. number of goals, is poisson distributed with parameter $\lambda_i$. We assume that these are independent between the observations. This is not that realistic since two teams playing against each other probably will affect each others chance of making a goal. 

Moreover we assume that the only factors who influence the number of goals are the defence team, the attack team and weather they play on the home field or not. This is a very simple model and one could imagine that factors such as weather, illness, ect. can make a difference. 

The parameter in the model is given by
$$
  \lambda_i = \exp(x_i^T\beta) =\exp(\eta_i) ,
$$
or equivalently,
$$
  \log(\lambda_i) = x_i^T\beta.
$$
Hence, the effect of covariates on the rate $\lambda$ is similar to the effects on the odds in the logit model, which is exponentially multiplicative. 

The estimates for attack implies how good a team is to score. This means one would want this to be large since that gives more expected goals. The estimate for defence implies how good a team is to defend. This one would want to be negative. The estimate for home says something about how playing at their homefield affects their ability to play well. 


##b)

If good teams play well both in attack and defence one would expect these parameters to be negatively correlated. BEGRUN HVORFOR VI TROR DET? 

```{r, include=TRUE}
cor.test(mod$coefficients[2:16], mod$coefficients[17:31]) #hva skjer med dummi parameteren? hva tenker du på her? Spurte Jarle og vi skal ikke sjekke opp mot home :) 
```
As one can see from the output above, the correlation is high. This supports the claim that attack and defence are negatively correlated. KOMMENTERE NOE MER HER? 

##c)
We now want to check if there is overdispersion in the data. To do so we estimate the overdispersion parameter $\phi$, which is given in problem $2b)$. We know this parameter is chisquared distributed with $352$ degrees of freedom so we use this to calculate the p-value.   
```{r, include=TRUE}
deviance <- deviance(mod)
n <- nrow(long)               #number of rows
p <- length(mod$coefficients) #number of estimated regression coefficients
df <- mod$df.residual #find degrees of freedom
phi <- deviance/ df 
phi
p_val = pchisq(deviance, df, lower.tail = FALSE)
p_val

```

This p-value is not significant and one can not conclude with overdispersion. Still possible sources of overdispersion could be correlated matches. POSSIBLE SOURCES OF UNDERDISPERSION? 

##d)
Now we want to make a function that gives us the teamrank based on the games played. 

```{r, include=TRUE}
#Making the function that takes the above data.frame as input, computes the total number of points given to each team, and returns the ranking of each team. 
team_rank <- function(predict_data,n){
  teams = predict_data$attack[1:16]
  teams_char = as.character(teams)
  zero <- rep(0,16)
  
  df <- data.frame("points" =zero , "conceded" = zero ,"goals"= zero, "diff" = zero)
  row.names(df) <- teams_char
  
  
  
  ### Check goals and conceded
  for (i in (1:n)){
    attack = as.character(predict_data$attack[i])
    defence = as.character(predict_data$defence[i])
    goals = predict_data$goals[i]
    df[attack, "goals"] = df[attack, "goals"] + goals
    df[defence, "conceded"] = df[defence, "conceded"] + goals
    
  }
  
  #Count points
  for (i in seq(1,n, by=2)){
    attack = as.character(long$attack[i])
    defence = as.character(long$defence[i])
    goals_attack = predict_data$goals[i]
    goals_defence = predict_data$goals[i+1]
    if (goals_attack > goals_defence){
      df[attack, "points"] = df[attack, "points"] + 3
    }
    else if(goals_attack < goals_defence){
      df[defence, "points"] = df[defence, "points"] + 3
    }
    else{
      df[defence, "points"] = df[defence, "points"] + 1
      df[attack, "points"] = df[attack, "points"] + 1
    }
    
  }
  
  for (team in teams_char){
    df[team, "diff"] = df[team, "goals"]-df[team, "conceded"]
  }
  
  #Get rank
  ranking = data.table::frank(df, -points, -diff, -goals, ties.method = "random")
  ranking
  
  return(ranking)
}

rank=team_rank(long, 384) 
teams = long$attack[1:16]
d=data.frame("Teams"=as.character(teams),"Rank"=rank)
d

```

##e)

Now we want to simulate the entire tippeliga a thousand times and then compute the ranking in each case before computing an average ranking per team.  

```{r, include=TRUE}
#Find the betas from our model
expected = (predict(mod, long, type="response"))

n=480 #Number of matches per tippeliga

#Construct empty rank_matrixes to fill in the rank for each tippeliga and a poisson
rank_matrix<- matrix(0,  16, 1000)
#Construct an empty matrix to fill inn the simulated results per game per tippeliga (480*1000) matrix
poisson_matrix <-matrix(0,  n, 1000)

set.seed(50)

#Fill the poisson_matrix with simulations of number of goals scored per game, do this thousand times for each match
for (i in (1:n)){
  poisson_matrix[i,] <- rpois(1000, expected[[i]])
}
#Using the function in point e), compute the ranking of each team and store this in a 1000×16 matrix. You should perhaps do this inside another function that inserts the simulated goals into the complete data frame which you then pass to your function from point d).

#Construct the ranking of each team based on each tippeliga
predict_long <- long 
for (i in (1:1000)){
  predict_long$goals = poisson_matrix[,i]
  rank_matrix[,i] <-team_rank(predict_long,n)
}
rank_matrix[,3]

```
```{r, include=TRUE}
#calculating mean
ex_fin_rank =rep(0,16)

for (i in (1:16)){
  sum = 0
  sum=sum(rank_matrix[i,])  
  sum = sum/1000
  ex_fin_rank[i] = sum
}

teams<-long$attack[1:16]
team_av_rank<-ex_fin_rank
av_result <- data.frame("Team"=as.character(teams),"Expected rank"=team_av_rank)
av_result
```

Her må vi forklare litt mer hva vi gjør, men tror jeg trenger en gjennomgang av hva som skjer først :) :) Har fikset litt opp nå, ble det bedre? 

##f)

One could assume that if each team is equally good at defence and attack that these parameters therefore should be equal in absolute value but of opposite sign. This is a linear hypothesis because it can be written as $C\beta = d$. When the $\beta_{attack}$ =$-\beta_{defence}$ this simply gives a $C$ matrix with two ones on every row, one at the place for the teams attack and one at the place for the teams defence. 

In the code below, the construction of C is shown as well as a wald test of this hypotheses.

```{r, include=TRUE}
library(MASS)
C<- matrix(0,15,32)
for (i in (1:15)){
  C[i,i+1] = 1
  C[i, i+16] = 1
}

d <- rep(0,15)
betahat <- as.matrix(coef(mod))

wald <- t(C %*% (betahat) - d) %*% ginv(C %*% vcov(mod) %*% t(C)) %*% (C %*% betahat - d)
wald
pchisq(wald, df=15, lower.tail=FALSE)
qchisq(1-alpha,df=15)  #bruk denne istedenfor? sjekk ut 
?pchisq
?solve
```
As one can see this gives a high p-value and we do not reject the nullhypothesis for any reasonable significance level. Hence, the simplification of the model to assume that the attack and defence strengths of each team are equal in absolute value but with opposite sign is reasonable. 






