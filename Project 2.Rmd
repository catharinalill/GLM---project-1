---
title: "TMA4315: Compulsory exercise 2" 
subtitle: "Aurora Hofman, Camilla Karlsen, Catharina Lilleengen" 
date: "`r format(Sys.time(), '%d.%m.%Y')`"
output: html_document
---


# Problem 1

```{r setup, include=TRUE}
  filepath <- "https://www.math.ntnu.no/emner/TMA4315/2018h/mountains"
  mount <- read.table(file = filepath, header = TRUE, col.names = c("height", 
      "prominence", "fail", "success"))
  attach(mount)
```
##a) 
From the given dataset we notice that we have grouped data. This means that every covariate vector, $\vec{x_i}$, with $i=1,\ldots,G$, in the design matrix $X$ that are identical, are grouped. In our case this means that every expedition group that has attempted to reach the same mountain falls in the same group. We assume that the number of groups $G$ is much less then the total number of observations $n = \sum \limits_{i=1}^{G} n_i$, where $n_i$ is the number of replicates of $\vec{x_i}$. This is reasonable to assume since there are far more expeditions with people who have attempted reaching a mountain in our dataset, than the number of mountains which is 113 in this case. Hence, $n$ is much larger than $G$.

The response variables $y_i$ are assumed to be independent given the covariates $x_{i1},\ldots, x_{ik}$. We also assume that each data $y_i$ are Bernoulli distributed with $P(y_i = 1) = \pi_i$. For the people attempting there is a certain probability of reaching each mountain which is $\pi_i$. So the attempt is either a success or fail. 

Because the response variables $y_i$ are independent, the absolute frequencies $n_i\bar{y_i}$ of grouped data are binomially distributed, with $E(n_i\bar{y_i}) = n_i\pi_i$ and $Var(n_i\bar{y_i}) = n_i\pi_i(1-\pi_i)$. Hence, we have a binary model because we have two response values, the number of successes and number of fails. The linear predictor in this case is 
$$
\eta_i = \beta_0 + \beta_1x_{i1} + \ldots + \beta_kx_{ik} = \mathbf{x_i}^T\mathbf{\beta}, 
$$
and $k=2$. This linear predictor is linked to $\pi_i$ via the response function $h(.)$ where, 
$$
  \pi_i = h(\eta_i).
$$
The canonical link function for a binary regression model is the logit model, which is given by
$$
  \pi_i = \frac{\exp({\eta_i})}{1+\exp({\eta_i})}.
$$
For the canonical link function the log-likelihood function is always concave so that if the maximum likelihood estimator exists it is always unique. Thus, we choose the logit  model as our link function. 

We now fit a glm modelling how the probability that an attempt at reaching a particular summit depends on its height and prominence. 
```{r, include=TRUE}
  mod <- glm(cbind(success,fail)~height+prominence, family=binomial(link = "logit"))
  summary(mod)
```

##b) 
By use of the observed deviance, we can estimate the overdispersion parameter $\phi$. We have, 
$$
  \hat{\phi} = \frac{D}{G-p}, 
$$
where $D$ is the deviance, $G$ is the number of groups and $p$ is the number of estimated regression coefficients. In the code below we estimate the observed deviance. 
```{r, include=TRUE}
  deviance <- deviance(mod)
  G <- nrow(mount)      #number of groups
  p <- ncol(mount)-1    #number of estimated regression coefficients
  phi <- deviance/(G-p)
  phi
  df <- G-p #find degrees of freedom
  p_val = pchisq(deviance, df, lower.tail = FALSE)
  p_val
```
From the output we see that $\hat{\phi}$ is larger than 1. We know the deviance is chisquared distributed and we have $G-p = 110$ degrees of freedom. When doing a p-test of the deviance we get that this is significant, thus we have overdispersion. Reasons for overdispersion can be unobserved heterogeneity and positive correlation between independent binary observations of the response variable. In this case, the data could be correlated e.g because of similar weather conditions. If the weather is nice in an area it would be easier reaching the summit of several mountains. Also, within a group the expeditions can be correlated because expeditions which are done when the weather is nice will be easier than the attempts when the weather is bad.
Another reason for correlation could be different physical conditions for the people on the different excursion.??
Because we have overdispersion we want to refit the model using a quasi-likelihood model. 

DEN KORRELASJONEN HER MÅ VI SPØRRE om !! Usikker på om de mener korrelasjon mellom ekspedisjoner på ulike fjell, eller ekspedisjoner innad på et fjell. 

```{r, include=TRUE}
  mod2 <- glm(cbind(success,fail)~height+prominence, family=quasibinomial(link = "logit"))
  summary(mod2)
```

##c) 
Now we want to choose the best model for our data. This means we compare models with all possible combinations of the covariates we have in our original model, hereby called the full model, and also including the model with only intercept and choose the best of them. To compare the models we look at the QAIC criterion which is given by, 
$$
  QAIC = -\frac{2l(\hat{\theta})}{\hat{\phi}} +2p, 
$$
where $l(\hat{\theta})$ is the likelihood function evaluated at the estimated regression coefficients. We let $\hat{\phi}$ be a common estimate of the overdispersion parameter under the full model, and we count $\phi$ as a estimated parameter. To compute the QAIC for the different models we start by computing the likelihood function after we have fitted non-quasi-likelihood models for the different combinations of covariates. 
```{r, include=TRUE}
  library(ISwR)

  #Full model
  likelihood = logLik(mod)
  QAIC_mod = -2*likelihood/phi+2*(p+1)
  QAIC_mod
  
  #Model with only height as covariate
  mod10 <- glm(cbind(success,fail)~height, family=binomial(link = "logit"))
  likelihood10 = logLik(mod10)
  QAIC_mod10 = -2*likelihood10/phi+2*(p)
  QAIC_mod10
  
  #Model with only prominence as covariate
  mod01 <- glm(cbind(success,fail)~prominence , family=binomial(link = "logit"))
  likelihood01 = logLik(mod01)
  QAIC_mod01 = -2*likelihood01/phi+2*(p)
  QAIC_mod01
  
  #Model with only intercept
  mod00 <- glm(cbind(success,fail)~1 , family=binomial(link = "logit"))
  likelihood00 = logLik(mod00)
  QAIC_mod00 = -2*likelihood00/phi+2*(p-1)
  QAIC_mod00
  
  #SKAL VI OGSÅ HA MED AIC FOR HVER MODEL HER??
```
By looking at the computed QAICs we see that the model with both covariates has the lowest value. Hence, we choose the full model. 

##d)
Now we want to test the significance of each term in the model using both Wald test and likelihood ratio test. 
```{r, include=TRUE}
drop1(mod2, test = "LRT")  
summary(mod2)

#Wald test
beta <- coef(mod2)
d <- c(0,0)
C <- rbind(c(0,1,0),
           c(0,0,1))

#OBS!!! Her skal testing av beta_0, tas vekk, skal kun ha to linjer. Må da ta vekk en kolonne og en rad i design matrix også!!!
wald <- t(C %*% beta - d) %*% solve(C %*% vcov(mod2) %*% t(C)) %*% (C %*% beta - d)
wald
pchisq(wald, df=3, lower.tail=FALSE)
```
By use of likelihood ratio test we see that each term in the model is significant. By comparing with the summary from the fitted model we see that both covariates are a bit less significant in the summary output. 
SPØR OM DET ER NOE MER SOM SKAL KOMMENTERES HER??

HVA MED Å SKRIVE NOE MER SOM DET ØVERSTE HER I STEDET FOR DET UNDER? OG ER DET RIKTIG SÅNN DRT STÅR NÅ?
In the Wald test, when we want to test the significance of the regression coefficients we have the linear null hypothesis $H_0: \beta_{height} = \beta_{prominence} = 0$, which can be written as $C\beta = d$. So, in the construction of the $C$-matrix we have a $2\times3$-matrix. From the result we can see that the p-value is much less than any reasonable significance level, say e.g 0.05. Hence, we reject the null hypothesis that the coefficient estimates are zero. Thus the coefficients are significant. 

By use of the Wald test we see that the p-value is much less than any reasonable significance level, say e.g 0.05. Hence, we reject the null hypothesis that the coefficient estimates are zero. Thus the coefficients are significant. 

SKAL DET GJØRES WALD TEST FOR HVER KOEFFESIENT FOR SEG SELV HER??? SPØR JARLE
HVA ER EGT FORSKJELLEN PÅ DE TESTENE HER? HVA SLAGS NULL HYPOTESER HAR VI I DE ULIKE TILFELLENE??

Our choice of link function was the logit model. To interpret the estimated regression coefficients we look at the odds, 
$$
  \frac{\pi_i}{1-\pi_i} = \frac{P(y_i=1 | x_i)}{P(y_i=0 | x_i)} = \exp(\beta_0)\cdot \exp(x_{i1}\beta_1)\cdot \ldots \cdot \exp(x_{ik}\beta_k) = \exp(\eta_i). 
$$
So, if we for example increase $x_{i2}$ by one unit to $x_{i2}+1$  and keep all the other covariates constant, then we have
$$
  \frac{\pi_i}{1-\pi_i} = \exp(\beta_0)\cdot \exp(x_{i1}\beta_1)\cdot \exp((x_{i2}+1)\beta_2)\cdot \ldots \cdot \exp(x_{ik}\beta_k)
$$
$$
  = \exp(\beta_0)\cdot \exp(x_{i1}\beta_1)\cdot \exp(x_{i2}\beta_2)\cdot\exp(\beta_2)\cdot \ldots \cdot \exp(x_{ik}\beta_k) = \exp(\eta_i) \cdot\exp(\beta_2).
$$
Hence, the odds changes by $\exp(\beta_2)$. So, if $\beta_2 >0$ then $P(y_i=1)/P(y_i=0)$ increases and if $\beta_2 < 0$ then $P(y_i=1)/P(y_i=0)$ decreases. Also, if $\beta_2 = 0$ then $P(y_i=1)/P(y_i=0)$ remain unchanged. Hence, the effect of the covariates on the odds is exponentially multiplicative. 

This can also be interpreted in terms of the log-odds, 
$$
\log\left(\frac{\pi_i}{1-\pi_i}\right) = \eta_i = x_i^T\beta.
$$
We then have a linear relationship, and if we now increase $x_{i2}$ by one unit to $x_{i2}+1$ and keep all the other covariates constant, then the log-odds will change with a factor of $\beta_2$ as shown below. 
$$
\log\left(\frac{\pi_i}{1-\pi_i}\right) =  \beta_0 + \beta_1x_{i1} + \beta_2(x_{i2}+1) + \ldots + \beta_kx_{ik} = x_i^T\beta + \beta_2. 
$$
   
##e) 
```{r, include=TRUE}
library(ggplot2)
#Plotting the deviance residuals against fitted values
data = data.frame(fitted = mod2$fitted.values, res = residuals(mod2,type = "deviance"))
ggplot(data,aes(x=fitted,y = res)) + geom_point()
#Plotting the deviance residuals against the covariate height
data2 = data.frame(height, res = residuals(mod2,type = "deviance"))
ggplot(data2,aes(x=height,y = res)) + geom_point()
#Plotting the deviance residuals against the covariate prominence
data3 = data.frame(prominence, res = residuals(mod2,type = "deviance"))
ggplot(data3,aes(x=prominence,y = res)) + geom_point()

```
   
When plotting the fitted values against the residuals one can see that the data points does seem to be quite randomly spread around the horizontal axis $y=0$. Hence, we can conclude that our model fits good to our data. It also seems like the variance increase, so we do not have homoscedasisty, which means that each response in this case do not have the same variance. This is a contradiction of our assumption that the responses is Bernoulli distributed with the same variance. 

From this residual plot we can also detect possible outliers. The two data points to the left in the plot might seem like they are outliers, but it can also be that we have too few data points in this area to give an reasonable explanation. 

In the figure with the covariate height plotted against the residuals we see no systematic effect, e.g. linear or quadratic trend in the plot. Thus, we cannot say anything about how this covariate will affect the model. The same applies for the covariate prominence when we plot this against the residuals. 
   
##f) 

The height and the prominence of Mount Everest are both 8848 meters. We start by computing a prediction for the probability that an attempt at the summit will be successfull. Then we compute a 95% confidence interval for the predicted value on this scale based on asymptotic normality of $\beta$. We have assumed the responses to be Bernoulli distributed, but when $n$ is large they are approximately normal distributed. Hence, $\beta$ is asymptotic normal distributed.

In mathematical notation we find the confidence interval of $x_{new}^T\beta$, where $x_{new} = [1,8848,8848]^T$ which is the covariate vector for Mount Everest. Since we assume $\beta$ is asymptotic normal distributed we know the linear combination $x_{new}^T\beta$ is univariate normal distributed. So by rules of expected value and variance we have,
$$
  x_{new}^T\beta \sim N(x_{new}^T\hat{\beta},x_{new}^T\Sigma x_{new} ),
$$
where $\Sigma = Cov(\hat{\beta})$. Hence, we get a confidence interval
$$
  [x_{new}^T\hat{\beta} - z_{\alpha/2}\cdot SE(\hat{\beta}), x_{new}^T\hat{\beta} + z_{\alpha/2}\cdot SE(\hat{\beta})], 
$$
where $SE(\hat{\beta}) = \sqrt{x_{new}^T\Sigma x_{new}}$.

```{r, include=TRUE}
#Calculate CI for a predicted value
new = data.frame(height = 8848, prominence = 8848)
x_new = c(1,8848,8848)
pred = predict(mod2,newdata=new)            #The predicted probability
pred_value = plogis(pred)
pred_value

alpha=0.05
sigma_matrix= vcov(mod2)                    #The estimated variance matrix of β
se = sqrt(t(x_new)%*%sigma_matrix%*%x_new)  #Standard error of x^T*β

lower = pred - qnorm(1-alpha/2) * se
upper = pred + qnorm(1-alpha/2) * se
ci = c(lower, upper)      #95% confidence interval for the predicted value 
probci = plogis(ci)       #Transform the confindence interval to probability 
probci                    # scale
```
The predicted value for the probability of success in an attempt reaching the summit of Mount Everest is $p=0.089$. This is quite low, but it is at least reasonable that the probability of reaching the summit of the World´s higest mountain is low. 

In the code above we also found the confidence interval in terms of the linear predictor $\eta = x^T\beta$. To transform the interval to the probability scale we have used the inverse of the logit function. Hence to transform the confidence interval we have used that, 
$$
  \pi = \frac{\exp(\eta)}{1+\exp(\eta)}.
$$
We then get the interval [0.034,0.213]. 

```{r, include=TRUE}
#Calculate CI for highest mountain in data set
new_1 = data.frame(height = 8611, prominence = 4017)
x_1 = c(1,8611,4017)
pred_1 = predict(mod2,newdata=new_1) 
pred_value1 = plogis(pred_1)
pred_value1
se_1 = sqrt(t(x_1)%*%sigma_matrix%*%x_1)  #Standard error of x^T*β

lower_1 = pred_1 - qnorm(1-alpha/2) * se_1
upper_1 = pred_1 + qnorm(1-alpha/2) * se_1
ci_1 = c(lower_1, upper_1)  #95% confidence interval for the predicted value 
probci = plogis(ci_1)       #Transform the confindence interval to probability 
probci  
  
```

Mount Everest is the only mountain in our data set that have the same height and prominence. The higher the prominence the lower the probability of success. So, in this case since Mount Everest has such a high prominence, the predicted probability of success will be low. Also, here the prominence of Mount Everest does not tell us that much, because success of reaching the summit depend on where you start, and in this case the first basecamp of Mount Everst is about 5000 meters over sea level. For the other data, i.e. the other mountains, the prominence tells us more about how many meters you have to hike, and therefore gives a better interpretation of the difficulty of reaching the summit and thus the probability of success. This might lead to that the model does not fit the datapoint $x_{new}$ for Mount Everest well. Thus, we might get a predicted value and an interval that is not that reasonable. 

By comparing with the highest mountain in our data set, which have covariate vector $x_{1} = [1,8611,4017]^T$, we would expect that the probabilities of success for these two mountains are not that far from each other. The interval for the highest mountain in our data set is [0.180,0.337]. In addition, when calculating a confidence interval for Mount Everest, but letting the prominence be more similar to other mountains in Himalaya, e.g. 5000 instead, we get a interval of [0.099,0.249]. This is much more similiar to the interval for the highest mountain. Hence, we see a tendence of that our interval [0.034,0.213] gives a bit too low values.
   
# Problem 2

In this problem we want to use a generalized linear model to analyse part of the 2018 results from the Norwegian elite football league. 
```{r, include=TRUE}
long <- read.csv("https://www.math.ntnu.no/emner/TMA4315/2019h/eliteserie.csv")
```
##a)
We start by fitting a model with attack, defence and home as covariates, to the data.
```{r, include=TRUE}
mod <- glm(goals ~ attack + defence + home, poisson(link= log), data=long ) #log natural choice of link funk
summary(mod)
```

We choose the log-linear model as our link function since this is the natural choice for a poisson distribution. Further we assume that the response variables $y_i$, i.e. number of goals, is poisson distributed with parameter $\lambda_i$. We assume that these are independent between the observations. This is not that realistic since two teams playing against each other probably will affect each others chance of making a goal. So, pairwise observations will come from the same match, and will thus most likely be correlated.  

Moreover we assume that the only factors who influence the number of goals are the defence team, the attack team and weather they play on the home field or not. This is a very simple model and one could imagine that factors such as weather, illness, ect. can make a difference. 

The parameter in the model is given by
$$
  \lambda_i = \exp(x_i^T\beta) =\exp(\eta_i) ,
$$
or equivalently,
$$
  \log(\lambda_i) = x_i^T\beta.
$$
Hence, the effect of covariates on the rate $\lambda$ is similar to the effects on the odds in the logit model, which is exponentially multiplicative. 

The estimates for attack implies how good a team is to score. This means one would want this to be large since that gives more expected goals. The estimate for defence implies how good a team is to defend. This one would want to be as negative as possible. The estimate for home says something about how playing at their homefield affects the teams ability to play well. 

##b)

If good teams play well both in attack and defence one would expect these parameters to be negatively correlated. This is because if a team is good in attack then $\beta_{attack}$ will be large and positive, and if it is good in defence then $\beta_{defence}$ will be large and negative. Thus, we get a negative correlation. The same applies if a team is bad in both attack and defence. 

```{r, include=TRUE}
cor.test(mod$coefficients[2:16], mod$coefficients[17:31]) 
```
As one can see from the output above, the correlation is high. This supports the claim that attack and defence are negatively correlated. This could be a possible source for overdispersion which we will look at next. 

##c)
We now want to check if there is overdispersion in the data. To do so we estimate the overdispersion parameter $\phi$, which is given in problem $1b)$. We know the deviance is chisquared distributed and from the summary we can see we have $352$ degrees of freedom, so we use this to calculate the p-value.  
```{r, include=TRUE}
deviance <- deviance(mod)
n <- nrow(long)               #number of rows
p <- length(mod$coefficients) #number of estimated regression coefficients
df <- mod$df.residual #find degrees of freedom
phi <- deviance/ df 
phi
p_val = pchisq(deviance, df, lower.tail = FALSE)
p_val

```

Since $\hat{\phi}$ is right above 1 we observe a tendency of overdispersion, but when calculating the p-value we see that this is not significant and one can not conclude with overdispersion. Still possible sources of underdispersion and overdispersion could be correlated matches and correlation between the defence and attack parameter. Another source can be if one have not included all the covariates that influence the response. Hence, in this case it seems that this simple model with only three covariates is a good enough model. 

##d)
Now we want to make a function that gives us the teamrank based on the games played. 

```{r, include=TRUE}
#Making the function that takes the above data.frame as input, computes the total number of points given to each team, and returns the ranking of each team. 
team_rank <- function(predict_data,n){
  teams = predict_data$attack[1:16]
  teams_char = as.character(teams)
  zero <- rep(0,16)
  
  df <- data.frame("points" =zero , "conceded" = zero ,"goals"= zero, "diff" = zero)
  row.names(df) <- teams_char
  
  ### Check goals and conceded
  for (i in (1:n)){
    attack = as.character(predict_data$attack[i])
    defence = as.character(predict_data$defence[i])
    goals = predict_data$goals[i]
    df[attack, "goals"] = df[attack, "goals"] + goals
    df[defence, "conceded"] = df[defence, "conceded"] + goals
  }
  
  #Count points
  for (i in seq(1,n, by=2)){
    attack = as.character(long$attack[i])
    defence = as.character(long$defence[i])
    goals_attack = predict_data$goals[i]
    goals_defence = predict_data$goals[i+1]
    if (goals_attack > goals_defence){
      df[attack, "points"] = df[attack, "points"] + 3
    }
    else if(goals_attack < goals_defence){
      df[defence, "points"] = df[defence, "points"] + 3
    }
    else{
      df[defence, "points"] = df[defence, "points"] + 1
      df[attack, "points"] = df[attack, "points"] + 1
    }
  }
  
  for (team in teams_char){
    df[team, "diff"] = df[team, "goals"]-df[team, "conceded"]
  }
  
  #Get rank
  ranking = data.table::frank(df, -points, -diff, -goals, ties.method = "random")
  ranking
  
  return(ranking)
}

rank=team_rank(long, 384) 
teams = long$attack[1:16]
d=data.frame("Teams"=as.character(teams),"Rank"=rank)
d  

```

##e)

Now we want to simulate the entire tippeliga a thousand times and then compute the ranking in each case before computing an average ranking per team.  

```{r, include=TRUE}
#Find the beta´s from our model
expected = (predict(mod, long, type="response")) 

n=480 #Number of matches per tippeliga

#Construct empty rank_matrix to fill in the rank for each tippeliga simulated
rank_matrix<- matrix(0,  16, 1000)
#Construct an empty matrix to fill in the simulated results per game per tippeliga (480*1000) matrix
poisson_matrix <-matrix(0,  n, 1000)

set.seed(50)

#Fill the poisson_matrix with simulations of number of goals scored per game, do this thousand times for each match
for (i in (1:n)){
  poisson_matrix[i,] <- rpois(1000, expected[[i]])
}

#Construct the ranking of each team based on each tippeliga and store this in the rank_matrix 
predict_long <- long 
for (i in (1:1000)){
  predict_long$goals = poisson_matrix[,i]
  rank_matrix[,i] <-team_rank(predict_long,n)
}

#Calculate the expected rank
ex_fin_rank =rep(0,16)

for (i in (1:16)){
  sum = 0
  sum=sum(rank_matrix[i,])  
  sum = sum/1000
  ex_fin_rank[i] = sum
}

teams<-long$attack[1:16]
team_av_rank<-ex_fin_rank
av_result <- data.frame("Team"=as.character(teams),"Expected rank"=team_av_rank)
av_result_sorted <-av_result[order(av_result$Expected),] #order the dataframe by the expected rank 
av_result_sorted 
```
From the output above we see that Rosenborg has the highest expected rank. 

##f)

One could assume that if each team is equally good at defence and attack these parameters should be equal in absolute value, but of opposite sign. This is a linear hypothesis because it can be written as $C\beta = d$. When $\beta_{attack}$ =$-\beta_{defence}$ this simply gives a $C$-matrix with two ones in every row, one at the place for the teams attack and one at the place for the teams defence. 

In the code below, the construction of C is shown as well as a wald test of this hypotheses.
```{r, include=TRUE}
C<- matrix(0,15,32)
for (i in (1:15)){
  C[i,i+1] = 1  
  C[i, i+16] = 1
}

d <- rep(0,15)
betahat <- as.matrix(coef(mod))
wald <- t(C %*% (betahat) - d) %*% solve(C %*% vcov(mod) %*% t(C)) %*% (C %*% betahat - d)
wald
pchisq(wald, df=15, lower.tail=FALSE)
 
```
As one can see this gives a high p-value and we do not reject the null hypothesis for any reasonable significance level, say e.g. 0.05. Hence, the hypothesis of possibly doing a simplification of the model and assuming that the attack and defence strengths of each team are equal in absolute value but with opposite sign cannot be rejected. 






